{
    "header": "You are a vision-language model watching a human wash dishes.\nYou are given annotations of what actions are being done.\nYour task is to identify the state of the environment describing any and all relevant objects before each action is performed\nAdd unique identifiers to each object, and add any missing state-action annotations that make logical sense.\nIf a type of object repeats, it might be a different object. e.g. spoon_1, spoon_2, etc.",
    "example": {
        "conversations": [
            [
                {
                    "from": "human",
                    "value": "pick up mug\nmove from desk to sink\nturn on tap\npick up scrub\nscrub mug\nrinse mug till clean\nturn off tap\nplace mug on kitchentop\nend\n"
                },
                {
                    "from": "gpt",
                    "value": "[state 1]\nat(`desk_1`); on(`mug_1`, `desk_1`)\n[action 1]\npick up mug_1\n[state 2]\ninhand(`mug_1`); isdirty(`mug_1`)\n[action 2]move from desk_1 to sink_1\n[state 3]\nat(`sink_1`);isoff(`tap_1`)\n[action 3]\nturn on tap_1\n[state 4]\nison(`tap_1`)\n[action 4]\npick up scrub_1\n[state 5]\ninhand(`scrub_1`)\n[action 5]\nscrub mug_1\n[state 6]\nsoapy(`mug_1`)\n[action 6]\nrinse mug_1 till clean\n[state 7]\nclean(`mug_1`)\n[action 7]\nturn off tap_1\n[state 8]\nat(`kitchentop_1`)\n[action 8]\nplace mug_1 on kitchentop_1\n[state 9]\non(`mug_1`, `kitchentop_1`)\n[action 9] end\n"
                }
            ]
        ]
    },
    "prompts": []
}